(* Content-type: application/vnd.wolfram.mathematica *)

(*** Wolfram Notebook File ***)
(* http://www.wolfram.com/nb *)

(* CreatedBy='Wolfram 14.1' *)

(*CacheID: 234*)
(* Internal cache information:
NotebookFileLineBreakTest
NotebookFileLineBreakTest
NotebookDataPosition[       154,          7]
NotebookDataLength[     20522,        440]
NotebookOptionsPosition[     17831,        380]
NotebookOutlinePosition[     18255,        397]
CellTagsIndexPosition[     18212,        394]
WindowFrame->Normal*)

(* Beginning of Notebook Content *)
Notebook[{
Cell[TextData[{
 StyleBox["Mohamed M. Hammad",
  FontFamily->"FZLanTingHei-DB-GBK",
  FontSize->12,
  FontWeight->"Regular",
  FontColor->RGBColor[
   0.8488288700694285, 0.3848325322346838, 0.1479972533760586]],
 StyleBox["\[LineSeparator]",
  FontSize->12,
  FontColor->RGBColor[1, 0.5, 0]],
 StyleBox["\n",
  FontSize->12,
  FontSlant->"Italic",
  FontColor->RGBColor[1, 0.5, 0]],
 StyleBox["Neural Network and Deep Learning with Mathematica                  \
            ",
  FontFamily->"Arial Unicode MS",
  FontSize->17.5,
  FontWeight->"Regular",
  FontColor->RGBColor[
   0.9866483558403907, 0.9388876173037308, 0.6336003662165255]],
 StyleBox[ButtonBox["<",
  BaseStyle->"Hyperlink",
  ButtonData->{
    FrontEnd`FileName[{$RootDirectory, "Users", "fengh", "Documents", "RDS", 
      "EDITED", "Neural_NetWork_and_Deep_Learning"}, "NNDL-06-lr-gdv.nb", 
     CharacterEncoding -> "UTF-8"], None},
  ButtonNote->
   "/Users/fengh/Documents/RDS/EDITED/Neural_NetWork_and_Deep_Learning/NNDL-\
06-lr-gdv.nb"],
  FontFamily->"Arial Unicode MS",
  FontSize->17.5,
  FontWeight->"Regular",
  FontColor->RGBColor[
   0.9866483558403907, 0.9388876173037308, 0.6336003662165255]],
 StyleBox[" ",
  FontFamily->"Arial Unicode MS",
  FontSize->17.5,
  FontWeight->"Regular",
  FontColor->RGBColor[
   0.9866483558403907, 0.9388876173037308, 0.6336003662165255]],
 StyleBox[ButtonBox[">",
  BaseStyle->"Hyperlink",
  ButtonData->{
    FrontEnd`FileName[{$RootDirectory, "Users", "fengh", "Documents", "RDS", 
      "EDITED", "Neural_NetWork_and_Deep_Learning"}, "NNDL-08-regular.nb", 
     CharacterEncoding -> "UTF-8"], None},
  ButtonNote->
   "/Users/fengh/Documents/RDS/EDITED/Neural_NetWork_and_Deep_Learning/NNDL-\
08-regular.nb"],
  FontFamily->"Arial Unicode MS",
  FontSize->17.5,
  FontWeight->"Regular",
  FontColor->RGBColor[
   0.9866483558403907, 0.9388876173037308, 0.6336003662165255]],
 StyleBox["    ",
  FontFamily->"Arial Unicode MS",
  FontSize->17.5,
  FontWeight->"Regular",
  FontColor->RGBColor[
   0.9866483558403907, 0.9388876173037308, 0.6336003662165255]],
 StyleBox[ButtonBox["\[CapitalXi]",
  BaseStyle->"Hyperlink",
  ButtonData->{
    FrontEnd`FileName[{$RootDirectory, "Users", "fengh", "Documents", "RDS", 
      "EDITED", "Neural_NetWork_and_Deep_Learning"}, "contents.nb", 
     CharacterEncoding -> "UTF-8"], None},
  ButtonNote->
   "/Users/fengh/Documents/RDS/EDITED/Neural_NetWork_and_Deep_Learning/\
contents.nb"],
  FontFamily->"Arial Unicode MS",
  FontSize->17.5,
  FontWeight->"Regular",
  FontColor->RGBColor[
   0.9866483558403907, 0.9388876173037308, 0.6336003662165255]],
 StyleBox["\[LineSeparator]\[LineSeparator]",
  FontSize->12,
  FontSlant->"Italic",
  FontColor->RGBColor[1, 0.5, 0]],
 StyleBox["Edited by Hao Feng",
  FontFamily->"Futura",
  FontSize->12,
  FontWeight->"Medium",
  FontSlant->"Italic",
  FontColor->RGBColor[
   0.8488288700694285, 0.3848325322346838, 0.1479972533760586]]
}], "Text",
 CellMargins->{{66, -45}, {4, 12}},
 CellChangeTimes->{{3.9397640484222183`*^9, 3.939764052679113*^9}, 
   3.9397641564677134`*^9, 3.939764214184162*^9, {3.939774845841297*^9, 
   3.9397748486786137`*^9}, 3.9397769383984737`*^9, 3.939777524212697*^9, {
   3.939777679887363*^9, 3.9397776986053457`*^9}, 3.939777748637487*^9, {
   3.939777854556375*^9, 3.939777878635145*^9}, {3.9397779299447737`*^9, 
   3.9397779337440853`*^9}, {3.9397779656956463`*^9, 
   3.9397779872993917`*^9}, {3.939783995957651*^9, 3.9397839959644203`*^9}, 
   3.93994857128743*^9, {3.9403030753694696`*^9, 3.9403030753782463`*^9}, {
   3.940303217729404*^9, 3.940303217737211*^9}, {3.940741024123201*^9, 
   3.940741027365489*^9}, {3.940741081934002*^9, 3.940741081942062*^9}, {
   3.943567220607367*^9, 3.9435672414910088`*^9}, {3.94356735516547*^9, 
   3.943567355169693*^9}, {3.9435681597640142`*^9, 3.943568192257277*^9}, {
   3.94360553842068*^9, 3.943605549222768*^9}, {3.9450355549790707`*^9, 
   3.9450355549843817`*^9}, {3.945141528353572*^9, 3.945141528359885*^9}, {
   3.9451416722469597`*^9, 3.945141672252328*^9}},
 LineSpacing->{0.6999999999999997, 3},
 Background->RGBColor[
  0.13066300450141147`, 0.12460517280842298`, 0.4353551537346456],
 CellID->912160115,ExpressionUUID->"67aab6c7-b186-4fbc-a04a-683b7453f682"],

Cell[CellGroupData[{

Cell["7 Strategies for Generalization and Hyper-Parameter Tuning", "Section",
 CellChangeTimes->{{3.943567936366756*^9, 3.9435679403338757`*^9}, {
  3.94356810611018*^9, 3.9435681138472424`*^9}, {3.9436697752713633`*^9, 
  3.943669780056386*^9}, {3.944605092244577*^9, 3.9446051027689734`*^9}, {
  3.9450355605744457`*^9, 3.9450355732021914`*^9}, {3.945141494917075*^9, 
  3.945141507386279*^9}},
 CellID->622795188,ExpressionUUID->"4fba7fed-0087-40ae-a263-55e5b8fe4d49"],

Cell[TextData[{
 StyleBox["Remark:",
  FontWeight->"Bold"],
 "\[LineSeparator]This chapter provides a Mathematica implementation of the \
concepts and ideas presented in Chapter 6, [1], of the book titled ",
 ButtonBox["Artificial Neural Network and Deep Learning: Fundamentals and \
Theory",
  BaseStyle->"Hyperlink",
  ButtonData->{
    FrontEnd`FileName[{$RootDirectory, "Users", "fengh", "Documents", "RDS", 
      "EDITED", "Artifical_Neural_Network_and_Deep_Learning"}, "contents.nb", 
     CharacterEncoding -> "UTF-8"], None},
  ButtonNote->
   "/Users/fengh/Documents/RDS/EDITED/Artifical_Neural_Network_and_Deep_\
Learning/contents.nb"],
 ". We strongly recommend that you begin with the theoretical chapter to \
build a solid foundation before exploring the corresponding practical \
implementation."
}], "Note",
 CellChangeTimes->{{3.9435682523793507`*^9, 3.9435682907152853`*^9}, {
  3.9435754000406303`*^9, 3.943575400046158*^9}, {3.944605112751877*^9, 
  3.944605131151554*^9}, {3.94503559681851*^9, 3.945035597233686*^9}, {
  3.945141511691704*^9, 3.945141512098846*^9}},
 CellID->1196547533,ExpressionUUID->"2c93b86d-f330-4fb3-b295-cb7eba6efbe1"],

Cell["\<\
In this chapter, we delve into some of the most critical concepts and \
methodologies that form the backbone of machine learning, guiding the \
development of models that are not only powerful but also robust and \
generalizable across various scenarios. We focus on the aspects of Neural \
Network (NN) training that determine how effectively a model can generalize \
from training data to unseen data. Generalization is the ultimate test of a \
NN\[CloseCurlyQuote]s performance, assessing its ability to apply learned \
patterns to new datasets.\
\>", "Text",
 CellChangeTimes->{{3.945141704316698*^9, 3.945141728218478*^9}, {
  3.945141785513267*^9, 3.945141785555378*^9}},
 CellID->2141521949,ExpressionUUID->"5d5149f0-25f0-4649-a27d-6e9abc1d905e"],

Cell[CellGroupData[{

Cell["\<\
\[Bullet] We begin by addressing the fundamental challenges of overfitting \
and generalization. Overfitting occurs when the NN learns the details and \
noise in the training data to an extent that it negatively impacts the \
performance of NN on new data. Conversely, generalization refers to the model\
\[CloseCurlyQuote]s ability to apply what it has learned to unseen data. We \
will discuss strategies to balance this, including the importance of a robust \
model architecture.\
\>", "Item",
 CellChangeTimes->{{3.945141704316698*^9, 3.9451417308443003`*^9}, {
  3.945141785566978*^9, 3.945141785598607*^9}},
 CellID->914424814,ExpressionUUID->"f1dac95c-0e3c-4253-8dd7-e1dad9e198ae"],

Cell["\<\
\[Bullet] Next, we explore the bias-variance trade-off, a pivotal concept \
that helps in diagnosing the performance of machine learning algorithms. Bias \
refers to errors due to overly simplistic assumptions in the learning \
algorithm. Variance refers to errors from sensitivity to small fluctuations \
in the training set. High bias can cause a model to miss the relevant \
relations between features and target outputs (underfitting), whereas high \
variance can cause modeling the random noise in the training data \
(overfitting).\
\>", "Item",
 CellChangeTimes->{{3.945141704316698*^9, 3.945141732853598*^9}, {
  3.945141785608616*^9, 3.945141785638276*^9}},
 CellID->1162194144,ExpressionUUID->"765be931-a518-4ffb-950d-d8061a2ad423"],

Cell["\<\
\[Bullet] To assess a model\[CloseCurlyQuote]s generalization, we will split \
the data into three sets: training, validation, and testing [31- 38]. The \
training set is used to train the model, the validation set is used to tune \
the model\[CloseCurlyQuote]s hyperparameters and prevent overfitting, and the \
test set is used to evaluate the model\[CloseCurlyQuote]s performance as it \
simulates real-world, unseen data.\
\>", "Item",
 CellChangeTimes->{{3.945141704316698*^9, 3.945141734536745*^9}, {
  3.945141785648157*^9, 3.945141785668017*^9}},
 CellID->1539738794,ExpressionUUID->"9863945c-5eb4-4236-a60c-a4ce84a1ab59"],

Cell["\<\
\[Bullet] As we measure the success of our models, performance measures come \
into play. Common metrics [94-99] include accuracy, precision, recall, the F1 \
score for classification tasks, and mean squared error or mean absolute error \
for regression tasks. We will explore how these metrics can guide \
hyperparameter tuning.\
\>", "Item",
 CellChangeTimes->{{3.945141704316698*^9, 3.9451417362283087`*^9}, {
  3.945141785677999*^9, 3.945141785687944*^9}},
 CellID->500225917,ExpressionUUID->"4e502860-35b6-4245-84a5-604134ac7b72"],

Cell["\<\
\[Bullet] The practice of tuning hyperparameters is essential for optimizing \
model performance [100-108]. Techniques such as grid search and random search \
are popular methods for exploring the hyperparameter space. Grid search \
evaluates the model across a grid of hyperparameter combinations, while \
random search randomly selects combinations, offering a balance between \
exploration and exploitation.\
\>", "Item",
 CellChangeTimes->{{3.945141704316698*^9, 3.945141737968823*^9}, {
  3.945141785697949*^9, 3.945141785717895*^9}},
 CellID->890061014,ExpressionUUID->"f7c78097-86ff-404b-82be-dee13f224068"],

Cell["\<\
\[Bullet] Gaussian processes (GPs) [109-126] are a probabilistic model used \
in machine learning to predict the distribution of possible outcomes rather \
than just the best estimate. GPs are particularly useful for understanding \
model uncertainty, which can be leveraged for Bayesian optimization (BO) in \
hyperparameter tuning.\
\>", "Item",
 CellChangeTimes->{{3.945141704316698*^9, 3.9451417397811527`*^9}, {
  3.945141785728516*^9, 3.945141785748622*^9}},
 CellID->724272631,ExpressionUUID->"94b4b6b8-9fbb-47d2-a2b0-db23cfb0032a"],

Cell["\<\
\[Bullet] Further enhancing our toolkit for hyperparameter optimization, we \
will introduce tuning hyperparameters with BO. BO is a strategy for the \
global optimization of objective functions that are noisy, expensive to \
evaluate, or have no closed form. It is particularly useful for tuning \
hyperparameters in scenarios where evaluations are costly or time-consuming. \
BO uses past evaluation results to form a probabilistic model mapping \
hyperparameters to a probability of a score on the objective function.\
\>", "Item",
 CellChangeTimes->{{3.945141704316698*^9, 3.9451417417648*^9}, {
  3.945141785758669*^9, 3.945141785778762*^9}},
 CellID->428753227,ExpressionUUID->"dd6e16c4-e8a2-4760-a9e4-05e79922e6d6"],

Cell["\<\
\[Bullet] Lastly, we will discuss Acquisition Functions (ACFs). ACFs in BO \
are used to select the next set of hyperparameters to evaluate. Common ACFs \
include Expected Improvement (EI), Probability of Improvement (PI), and Upper \
Confidence Bound (UCB). These functions help in deciding which hyperparameter \
settings are likely to yield improvements over the best current observations.\
\
\>", "Item",
 CellChangeTimes->{{3.945141704316698*^9, 3.945141753493751*^9}, {
  3.945141785788883*^9, 3.945141785808989*^9}},
 CellID->1167084721,ExpressionUUID->"1202619c-c6e0-4721-9ccb-53922ab65ffe"]
}, Open  ]],

Cell["\<\
In this chapter, by leveraging Mathematica\[CloseCurlyQuote]s advanced \
functionalities, we will explore various techniques to optimize our models \
and enhance their predictive capabilities. The chapter is structured into \
five distinct units, each designed to progressively deepen the reader\
\[CloseCurlyQuote]s understanding and proficiency in constructing and \
optimizing NNs using Mathematica. From exploring the fundamental challenges \
of overfitting to mastering advanced techniques like BO, this chapter \
provides a step-by-step guide to refining predictive models and enhancing \
their performance in real-world scenarios.\
\>", "Text",
 CellChangeTimes->{{3.945141704316698*^9, 3.9451417456941767`*^9}, {
  3.945141785819065*^9, 3.9451417858595543`*^9}},
 CellID->1043528908,ExpressionUUID->"3cd49020-ab8e-4786-b96c-3c5895d11a5d"],

Cell[CellGroupData[{

Cell["\<\
\[Bullet] UNIT 7.1: The Fundamentals of Overfitting: What It Is and Why It \
Happens This unit begins by addressing the fundamental concept of \
overfitting, a common pitfall in NN training. Through illustrative examples \
and Mathematica simulations, we will learn how to recognize overfitting.\
\>", "Item",
 CellChangeTimes->{{3.945141704316698*^9, 3.94514171582111*^9}, {
  3.9451417600852327`*^9, 3.9451417858794394`*^9}},
 CellID->1883587931,ExpressionUUID->"f1d572f1-c1a9-4373-bc9c-475e26804b5f"],

Cell["\<\
\[Bullet] UNIT 7.2: Performance Metrics Understanding how to evaluate a NN is \
crucial. Performance metrics are the lens through which the effectiveness of \
NNs is viewed. This unit focuses on the various performance metrics available \
in Mathematica. For regression, common metrics include mean squared error, \
mean absolute error, root mean squared error, and R-squared. For \
classification, common metrics include accuracy, precision, recall \
(sensitivity), F1 score, and confusion matrix. During the training process, \
you can use the TrainingProgressMeasurements option in Mathematica to monitor \
these metrics and track the progress of your model. This provides valuable \
feedback on how well the model is learning and allows you to make adjustments \
as needed to improve its performance.\
\>", "Item",
 CellChangeTimes->{{3.945141704316698*^9, 3.94514171582111*^9}, {
  3.945141764777359*^9, 3.945141785959979*^9}},
 CellID->1369896829,ExpressionUUID->"7b3d2538-c416-46c6-9a98-be0e45bb3ea8"],

Cell["\<\
\[Bullet] UNIT 7.3: Gaussian Processes Implementation in Mathematica from \
Scratch GPs offer a robust probabilistic approach to modeling in machine \
learning. GPs indeed serve as a cornerstone in BO. This unit demonstrates how \
to implement GPs in Mathematica from scratch to provide insightful \
predictions and uncertainty estimations.\
\>", "Item",
 CellChangeTimes->{{3.945141704316698*^9, 3.94514171582111*^9}, {
  3.945141766412709*^9, 3.945141785989856*^9}},
 CellID->1240874857,ExpressionUUID->"34e7f22f-59b8-4959-965e-9bded12720ea"],

Cell["\<\
\[Bullet] UNIT 7.4: Setting Up BO in Mathematica The journey through NN \
optimization would be incomplete without addressing BO. BO is a powerful \
technique for optimizing expensive, black-box functions. With Mathematica\
\[CloseCurlyQuote]s BayesianMinimization and BayesianMaximization functions, \
we will explore how to apply this sophisticated approach to streamline the \
hyperparameter tuning process. Additionally, utilizing Mathematica\
\[CloseCurlyQuote]s GaussianProcess method, we will demonstrate how GPs can \
be implemented, in a simple way, to make predictive models.\
\>", "Item",
 CellChangeTimes->{{3.945141704316698*^9, 3.94514171582111*^9}, {
  3.945141769397727*^9, 3.945141786040059*^9}},
 CellID->1590987753,ExpressionUUID->"21f5ff34-a465-4852-a944-f1c7c258d6ed"],

Cell["\<\
\[Bullet] UNIT 7.5: Automated Hyperparameter Tuning with Mathematica Finally, \
the chapter concludes by discussing automated hyperparameter tuning \
techniques, harnessing Mathematica\[CloseCurlyQuote]s capabilities to \
simplify and accelerate the search for optimal model parameters. Techniques \
like grid search and random search, implemented through Mathematica\
\[CloseCurlyQuote]s versatile programming environment, will be showcased. \
Moreover, using Mathematica\[CloseCurlyQuote]s built-in functions \
BayesianMinimization and BayesianMaximization, we will explore how to \
automate the search for the best model parameters, thereby simplifying the \
model-building process and improving performance.\
\>", "Item",
 CellChangeTimes->{{3.945141704316698*^9, 3.94514171582111*^9}, {
  3.945141780059557*^9, 3.945141786100753*^9}},
 CellID->1703451807,ExpressionUUID->"696c08c6-259e-426a-a135-328b003f727f"]
}, Open  ]],

Cell["\<\
By the end of this chapter, readers will be equipped with a deep \
understanding and practical skills to leverage Mathematica for building and \
optimizing NNs, ready to tackle complex real-world data challenges.\
\>", "Text",
 CellChangeTimes->{{3.945141704316698*^9, 3.94514171582111*^9}, 
   3.9451417861108637`*^9},
 CellID->852326318,ExpressionUUID->"0a3b2d0a-55f6-499b-945a-136426d7b8f4"],

Cell["\<\
The Fundamentals of Overfitting: What It Is and Why It Happens\
\>", "Subsection",
 CellChangeTimes->{{3.9451419270333138`*^9, 3.945141938833342*^9}},
 CellID->1177866396,ExpressionUUID->"5d0ec960-d25a-444e-8ccf-5f3155b378d6"]
}, Open  ]]
},
WindowSize->{960, 1027},
WindowMargins->{{0, Automatic}, {Automatic, 0}},
Magnification:>1.25 Inherited,
FrontEndVersion->"14.1 for Mac OS X ARM (64-bit) (July 16, 2024)",
StyleDefinitions->"RDS-book.nb",
ExpressionUUID->"8861bace-5584-420b-8e0c-c51fd7c6d3a1"
]
(* End of Notebook Content *)

(* Internal cache information *)
(*CellTagsOutline
CellTagsIndex->{}
*)
(*CellTagsIndex
CellTagsIndex->{}
*)
(*NotebookFileOutline
Notebook[{
Cell[554, 20, 4263, 106, 130, "Text",ExpressionUUID->"67aab6c7-b186-4fbc-a04a-683b7453f682",
 CellID->912160115],
Cell[CellGroupData[{
Cell[4842, 130, 471, 6, 174, "Section",ExpressionUUID->"4fba7fed-0087-40ae-a263-55e5b8fe4d49",
 CellID->622795188],
Cell[5316, 138, 1163, 23, 190, "Note",ExpressionUUID->"2c93b86d-f330-4fb3-b295-cb7eba6efbe1",
 CellID->1196547533],
Cell[6482, 163, 763, 12, 222, "Text",ExpressionUUID->"5d5149f0-25f0-4649-a27d-6e9abc1d905e",
 CellID->2141521949],
Cell[CellGroupData[{
Cell[7270, 179, 698, 11, 137, "Item",ExpressionUUID->"f1dac95c-0e3c-4253-8dd7-e1dad9e198ae",
 CellID->914424814],
Cell[7971, 192, 752, 12, 162, "Item",ExpressionUUID->"765be931-a518-4ffb-950d-d8061a2ad423",
 CellID->1162194144],
Cell[8726, 206, 640, 10, 113, "Item",ExpressionUUID->"9863945c-5eb4-4236-a60c-a4ce84a1ab59",
 CellID->1539738794],
Cell[9369, 218, 545, 9, 113, "Item",ExpressionUUID->"4e502860-35b6-4245-84a5-604134ac7b72",
 CellID->500225917],
Cell[9917, 229, 624, 10, 137, "Item",ExpressionUUID->"f7c78097-86ff-404b-82be-dee13f224068",
 CellID->890061014],
Cell[10544, 241, 549, 9, 113, "Item",ExpressionUUID->"94b4b6b8-9fbb-47d2-a2b0-db23cfb0032a",
 CellID->724272631],
Cell[11096, 252, 732, 11, 162, "Item",ExpressionUUID->"dd6e16c4-e8a2-4760-a9e4-05e79922e6d6",
 CellID->428753227],
Cell[11831, 265, 609, 10, 113, "Item",ExpressionUUID->"1202619c-c6e0-4721-9ccb-53922ab65ffe",
 CellID->1167084721]
}, Open  ]],
Cell[12455, 278, 856, 13, 222, "Text",ExpressionUUID->"3cd49020-ab8e-4786-b96c-3c5895d11a5d",
 CellID->1043528908],
Cell[CellGroupData[{
Cell[13336, 295, 513, 8, 88, "Item",ExpressionUUID->"f1d572f1-c1a9-4373-bc9c-475e26804b5f",
 CellID->1883587931],
Cell[13852, 305, 1018, 15, 237, "Item",ExpressionUUID->"7b3d2538-c416-46c6-9a98-be0e45bb3ea8",
 CellID->1369896829],
Cell[14873, 322, 554, 9, 113, "Item",ExpressionUUID->"34e7f22f-59b8-4959-965e-9bded12720ea",
 CellID->1240874857],
Cell[15430, 333, 799, 12, 162, "Item",ExpressionUUID->"21f5ff34-a465-4852-a944-f1c7c258d6ed",
 CellID->1590987753],
Cell[16232, 347, 925, 14, 212, "Item",ExpressionUUID->"696c08c6-259e-426a-a135-328b003f727f",
 CellID->1703451807]
}, Open  ]],
Cell[17172, 364, 404, 7, 104, "Text",ExpressionUUID->"0a3b2d0a-55f6-499b-945a-136426d7b8f4",
 CellID->852326318],
Cell[17579, 373, 236, 4, 68, "Subsection",ExpressionUUID->"5d0ec960-d25a-444e-8ccf-5f3155b378d6",
 CellID->1177866396]
}, Open  ]]
}
]
*)

